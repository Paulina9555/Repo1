{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paulina9555/Repo1/blob/master/Wst%C4%99p_do_sieci_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obliczanie wag w sieci MLP"
      ],
      "metadata": {
        "id": "DwLhC3hpotQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby obliczyć liczbę parametrów w warstwie Dense w sieci neuronowej, musisz wziąć pod uwagę dwa rodzaje parametrów: wagi (weights) i obciążenia (biases). Warstwa Dense, nazywana także warstwą w pełni połączoną, jest jednym z podstawowych rodzajów warstw w sieciach neuronowych.\n",
        "\n",
        "Warstwa Dense składa się z wielu neuronów (zwanych także jednostkami lub węzłami). Każdy neuron w warstwie Dense jest połączony z każdym neuronem w poprzedniej warstwie (lub wejściowej warstwie, jeśli jest to pierwsza warstwa). Parametry dla każdego połączenia to waga i obciążenie. Oto jak obliczyć liczbę parametrów w warstwie Dense:\n",
        "\n",
        "1. Wagi (weights): Każde połączenie między neuronem w poprzedniej warstwie a neuronem w warstwie Dense ma swoją wagę. Jeśli warstwa Dense ma n neuronów, a poprzednia warstwa ma m neuronów, to liczba wag wynosi m * n. Każda waga jest liczbą rzeczywistą, co oznacza, że każda z nich ma przypisaną wartość numeryczną.\n",
        "\n",
        "2. Obciążenia (biases): Każdy neuron w warstwie Dense ma także przypisane obciążenie. Jeśli warstwa Dense ma n neuronów, to liczba obciążenia wynosi n. Obciążenia są również liczbami rzeczywistymi.\n",
        "\n",
        "Ostatecznie liczba parametrów w warstwie Dense to suma liczby wag i liczby obciążeń. Możemy to podsumować równaniem:\n",
        "\n",
        "Liczba parametrów = (Liczba neuronów w poprzedniej warstwie * Liczba neuronów w warstwie Dense) + Liczba neuronów w warstwie Dense\n",
        "\n",
        "Na przykład, jeśli masz warstwę Dense o rozmiarze 64 z poprzednią warstwą, która ma 128 neuronów, to liczba parametrów wynosi:\n",
        "\n",
        "Liczba parametrów = (128 * 64) + 64 = 8256\n",
        "\n",
        "To oznacza, że w tej warstwie jest 8256 parametrów, które będą uczone podczas treningu modelu."
      ],
      "metadata": {
        "id": "caGvbnGGn1lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8HoGLcVUdDDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "n_classes = 7\n",
        "# jakas tam siec MLP, inputow ma 14, do klasyfikacji 7-mio klasowej\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(25,input_shape=(14,), activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(36, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(47, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(n_classes, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Bto-PQhhdDVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1= 14*25+25\n",
        "w2 = 25*36+36\n",
        "w3 = 36*47+47\n",
        "w4=47*7+7\n",
        "print(w1,w2,w3,w4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEAT2z6Dd2tZ",
        "outputId": "68ccd4eb-a03b-4e14-df72-f22b254d6ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375 936 1739 336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gEbR2jvKeJHi",
        "outputId": "148e9d6a-63f7-47c0-fc6c-a14ae346e49c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 25)                375       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 36)                936       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 47)                1739      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3386 (13.23 KB)\n",
            "Trainable params: 3386 (13.23 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wczesne zatrzymywanie treningu"
      ],
      "metadata": {
        "id": "mA7eWWPzow_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping (wczesne zatrzymywanie) to technika regularyzacji używana podczas treningu modeli uczenia maszynowego, a w szczególności sieci neuronowych. Celem tej techniki jest uniknięcie przeuczenia modelu poprzez monitorowanie jego wydajności na zbiorze walidacyjnym podczas treningu i zatrzymywanie treningu, gdy model zaczyna się pogarszać na zbiorze walidacyjnym, zamiast kontynuować uczenie do momentu osiągnięcia zbieżności na zbiorze treningowym.\n",
        "\n",
        "Ogólny przebieg early stopping jest następujący:\n",
        "\n",
        "1. **Podziel dane na zbiór treningowy, walidacyjny i testowy**: Dzieli się dostępne dane na trzy zestawy. Zbiór treningowy służy do uczenia modelu, zbiór walidacyjny służy do monitorowania wydajności modelu podczas treningu, a zbiór testowy służy do ostatecznej oceny wydajności modelu po treningu.\n",
        "\n",
        "2. **Inicjalizacja modelu**: Inicjuje się model sieci neuronowej i inicjuje się parametry treningowe, takie jak szybkość uczenia (learning rate) i liczbę epok (iteracji przez zbiór treningowy).\n",
        "\n",
        "3. **Trening z monitorowaniem**: Model jest trenowany na zbiorze treningowym, a po każdej epoce obliczana jest jego wydajność na zbiorze walidacyjnym.\n",
        "\n",
        "4. **Monitorowanie wydajności na zbiorze walidacyjnym**: Podczas treningu śledzi się wyniki na zbiorze walidacyjnym. Jeśli wydajność na zbiorze walidacyjnym przestaje się poprawiać lub zaczyna się pogarszać, jest to sygnał do zatrzymania treningu.\n",
        "\n",
        "5. **Zatrzymanie treningu**: Kiedy wykryte zostaje pogorszenie się wydajności na zbiorze walidacyjnym, trening jest zatrzymywany, a model z najlepszymi osiągnięciami na zbiorze walidacyjnym jest zachowywany. Może to być model z dowolnej wcześniejszej epoki, w której wydajność na zbiorze walidacyjnym była najlepsza.\n",
        "\n",
        "Early stopping pomaga w uniknięciu przetrenowania (overfittingu) modelu, co może prowadzić do słabej zdolności generalizacji na nowe dane. Jest to szczególnie przydatne, gdy trening modelu trwa długo, a istnieje ryzyko, że model dostosuje się zbyt dokładnie do danych treningowych. Early stopping pozwala oszczędzić czas i zasoby, eliminując konieczność kontynuowania treningu po osiągnięciu optymalnej wydajności na zbiorze walidacyjnym."
      ],
      "metadata": {
        "id": "eJ43PAexoBfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby zastosować Early Stopping w TensorFlow, możesz skorzystać z callbacku o nazwie `EarlyStopping`. Ten callback monitoruje wydajność modelu na zbiorze walidacyjnym i zatrzymuje trening, gdy wydajność przestaje się poprawiać lub zaczyna się pogarszać. Oto jak to zrobić:\n",
        "\n",
        "\n",
        "1. Najpierw przygotuj dane treningowe, walidacyjne i testowe oraz zdefiniuj swoją sieć neuronową w TensorFlow.\n",
        "\n",
        "2. Importuj moduł `EarlyStopping` i skonfiguruj go podczas treningu modelu. Oto przykład:\n",
        "\n",
        "   ```python\n",
        "   import tensorflow as tf\n",
        "   from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "   # Przygotowanie danych treningowych, walidacyjnych i testowych\n",
        "   x_train, y_train = ...\n",
        "   x_val, y_val = ...\n",
        "\n",
        "   # Definicja modelu\n",
        "   model = tf.keras.models.Sequential([\n",
        "       # Dodaj warstwy modelu\n",
        "       # ...\n",
        "   ])\n",
        "\n",
        "   # Kompilacja modelu\n",
        "   model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "   # Konfiguracja EarlyStopping\n",
        "   early_stopping = EarlyStopping(\n",
        "       monitor='val_loss',    # Monitoruj funkcję straty na zbiorze walidacyjnym\n",
        "       patience=5,            # Zatrzymaj trening po 5 epokach bez poprawy\n",
        "       verbose=1,             # Wyświetl komunikaty o zatrzymaniu treningu\n",
        "       restore_best_weights=True  # Przywróć najlepsze wagi modelu po zatrzymaniu\n",
        "   )\n",
        "\n",
        "   # Rozpoczęcie treningu z użyciem callbacku EarlyStopping\n",
        "   history = model.fit(\n",
        "       x_train,\n",
        "       y_train,\n",
        "       epochs=100,\n",
        "       validation_data=(x_val, y_val),\n",
        "       callbacks=[early_stopping]  # Dodaj callback do monitorowania treningu\n",
        "   )\n",
        "   ```\n",
        "\n",
        "W powyższym kodzie:\n",
        "- `monitor` określa, co będzie monitorowane podczas treningu. W tym przypadku monitorujemy funkcję straty na zbiorze walidacyjnym (`'val_loss'`).\n",
        "- `patience` określa, ile epok bez poprawy musi minąć, zanim trening zostanie zatrzymany.\n",
        "- `verbose` określa, czy chcesz widzieć komunikaty o zatrzymaniu treningu (ustawione na `1` wyświetli komunikat).\n",
        "- `restore_best_weights` po zatrzymaniu treningu przywraca najlepsze wagi modelu zapisane podczas treningu.\n",
        "\n",
        "Dzięki temu setupowi trening zostanie zatrzymany, gdy model przestanie się poprawiać na zbiorze walidacyjnym, co pomaga uniknąć przeuczenia i oszczędza czas treningu."
      ],
      "metadata": {
        "id": "E9n9IyrSoMPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dodatek Tensorboard"
      ],
      "metadata": {
        "id": "tloLFMBFo0SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorBoard to narzędzie do wizualizacji i monitorowania procesu treningu modeli uczenia maszynowego w TensorFlow, popularnym frameworku do głębokiego uczenia. Jest to potężne narzędzie, które pomaga w analizie i zrozumieniu zachowania modelu w trakcie treningu poprzez prezentację różnych metryk, wykresów, histogramów i grafów.\n",
        "\n",
        "Oto kilka głównych funkcji i zastosowań TensorBoard:\n",
        "\n",
        "1. **Wizualizacja metryk treningowych**: TensorBoard pozwala na śledzenie różnych metryk, takich jak funkcja straty (loss), dokładność (accuracy), czy dowolne inne metryki, które są zbierane podczas treningu. Wykresy i przebiegi metryk są prezentowane w czasie rzeczywistym, co pozwala monitorować postęp treningu.\n",
        "\n",
        "2. **Wykresy histogramów wag**: Możesz przeglądać rozkłady wag w poszczególnych warstwach modelu. To pomaga zrozumieć, jak zmieniają się wagi podczas treningu i czy występują problemy związane z ich zbieżnością.\n",
        "\n",
        "3. **Wizualizacja grafu modelu**: TensorBoard umożliwia wyświetlanie grafu obliczeń modelu, co ułatwia zrozumienie jego architektury i struktury. Możesz przejrzeć całą strukturę modelu, włącznie z warstwami i połączeniami między nimi.\n",
        "\n",
        "4. **Wizualizacja dystrybucji aktywacji**: Możesz analizować dystrybucję aktywacji w poszczególnych warstwach modelu. To pomaga w zrozumieniu, czy występują problemy z eksplodującym lub zanikającym gradientem.\n",
        "\n",
        "5. **Projekcje T-SNE**: TensorBoard pozwala na projekcje danych treningowych w przestrzeń niższego wymiaru (na przykład 2D lub 3D) za pomocą algorytmu T-SNE. To umożliwia wizualizację rozkładu danych w bardziej zrozumiały sposób.\n",
        "\n",
        "6. **Porównywanie różnych treningów**: Możesz porównywać różne przebiegi treningu, eksperymenty i modele, aby wybrać najlepszą konfigurację i śledzić postępy w ulepszaniu modelu.\n",
        "\n",
        "7. **Zapisywanie logów treningowych**: TensorBoard zapisuje logi z metrykami i innymi danymi treningowymi w specjalnym formacie, który można później odtwarzać i analizować.\n",
        "\n",
        "TensorBoard jest częścią pakietu TensorFlow i jest łatwo dostępny, gdy masz zainstalowany TensorFlow. Możesz go uruchomić z poziomu wiersza poleceń, a następnie przeglądać interaktywną wizualizację w przeglądarce internetowej. Jest to ważne narzędzie w procesie rozwoju modeli uczenia maszynowego i pomaga w usprawnieniu i zoptymalizowaniu treningu."
      ],
      "metadata": {
        "id": "lFxBBS_Tohu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby zastosować TensorBoard w Google Colab, możesz skorzystać z kilku kroków:\n",
        "\n",
        "4. **Konfiguracja TensorBoard**:\n",
        "   Przygotuj callback TensorBoard, który będzie monitorować postęp treningu i zapisywać logi TensorBoard.\n",
        "\n",
        "   ```python\n",
        "   # Ustaw katalog, w którym będą zapisywane logi TensorBoard\n",
        "   log_dir = \"logs/\"\n",
        "\n",
        "   # Przygotuj callback TensorBoard\n",
        "   tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "   ```\n",
        "\n",
        "   Możesz dostosować `log_dir` do własnych preferencji.\n",
        "\n",
        "5. **Trening modelu**:\n",
        "   Trenuj swój model z użyciem callbacku TensorBoard:\n",
        "\n",
        "   ```python\n",
        "   model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val), callbacks=[tensorboard_callback])\n",
        "   ```\n",
        "\n",
        "6. **Uruchomienie TensorBoard w Colab**:\n",
        "   Teraz możesz uruchomić TensorBoard w Colab, wykonując poniższą komórkę:\n",
        "\n",
        "   ```python\n",
        "   %tensorboard --logdir logs/\n",
        "   ```\n",
        "\n",
        "   Ta komórka uruchomi TensorBoard i wyświetli interaktywną wizualizację w Colab. Możesz przeglądać wykresy, histogramy, wykresy rozkładu i inne informacje związane z treningiem modelu.\n",
        "\n",
        "7. **Kontrola TensorBoard**:\n",
        "   Po uruchomieniu TensorBoard w Colab, otrzymasz link do dostępu do TensorBoard w przeglądarce internetowej w Colab. Możesz korzystać z różnych opcji wizualizacji i analizy treningu modelu.\n",
        "\n",
        "To jest ogólny przewodnik dotyczący korzystania z TensorBoard w Colab. Dzięki temu narzędziu możesz lepiej zrozumieć zachowanie swojego modelu w trakcie treningu i zoptymalizować go."
      ],
      "metadata": {
        "id": "iyVURGn2oriO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zapisywanie i wczytywanie gotowego modelu"
      ],
      "metadata": {
        "id": "V78NSofKo3q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W TensorFlow istnieją różne sposoby zapisywania modelu. Jednym z najpopularniejszych i rekomendowanych jest zapisywanie modelu za pomocą API Keras, które jest częścią TensorFlow. Oto przykład, jak zapisać i załadować model w TensorFlow:\n",
        "\n",
        "### Zapisywanie modelu\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Przykładowy model Keras\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trening modelu (dla celów ilustracyjnych)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "model.fit(x_train.reshape(-1, 784), y_train, epochs=5)\n",
        "\n",
        "# Zapisz model do katalogu \"my_model\"\n",
        "model.save('my_model')\n",
        "```\n",
        "\n",
        "W powyższym przykładzie używamy metody `save` obiektu modelu, aby zapisać model w katalogu o nazwie \"my_model\". Model zostanie zapisany w formacie HDF5, który jest obsługiwany przez TensorFlow i wiele innych narzędzi do uczenia maszynowego.\n",
        "\n",
        "### Ładowanie zapisanego modelu\n",
        "\n",
        "Aby załadować zapisany model, możesz użyć funkcji `load_model` z modułu `keras.models`:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Ładuj model z katalogu \"my_model\"\n",
        "loaded_model = load_model('my_model')\n",
        "\n",
        "# Przykładowe dane testowe\n",
        "(x_test, y_test) = tf.keras.datasets.mnist.load_data()[1]\n",
        "\n",
        "# Dokonaj predykcji załadowanym modelem\n",
        "predictions = loaded_model.predict(x_test.reshape(-1, 784))\n",
        "\n",
        "# Możesz kontynuować pracę z załadowanym modelem\n",
        "```\n",
        "\n",
        "Po załadowaniu modelu możesz użyć go do przewidywania, ewaluacji lub kontynuacji treningu (jeśli to ma sens w kontekście twojego zadania)."
      ],
      "metadata": {
        "id": "_Y5Y8MafpFMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format HDF5 (Hierarchical Data Format version 5) jest otwartym standardem do przechowywania i organizacji dużych ilości danych, szczególnie używany w dziedzinie nauki danych, uczenia maszynowego i przetwarzania sygnałów. Poniżej przedstawiam jego główne cechy i zalety:\n",
        "\n",
        "**1. Hierarchiczna struktura danych:** Format HDF5 pozwala na przechowywanie danych w hierarchiczny sposób, podobny do struktury drzewa. Dane mogą być grupowane wewnątrz grup, co umożliwia łatwą organizację dużych zbiorów danych.\n",
        "\n",
        "**2. Obsługa różnych typów danych:** HDF5 obsługuje wiele różnych typów danych, w tym liczby całkowite, liczby zmiennoprzecinkowe, napisy, tablice wielowymiarowe i wiele innych. To sprawia, że jest to format wszechstronny, który może być używany do przechowywania różnorodnych danych.\n",
        "\n",
        "**3. Wsparcie dla kompresji:** Format HDF5 umożliwia kompresję danych, co może znacząco zmniejszyć rozmiar plików, co jest szczególnie przydatne, gdy pracujesz z dużymi zbiorami danych.\n",
        "\n",
        "**4. Wsparcie dla metadanych:** Możesz dołączać metadane do plików HDF5, co ułatwia opisywanie i dokumentowanie zawartości plików.\n",
        "\n",
        "**5. Przenośność:** Pliki HDF5 są przenośne, co oznacza, że można je otwierać i odczytywać na wielu platformach i w różnych językach programowania. Istnieją biblioteki i narzędzia do obsługi HDF5 w wielu popularnych językach, takich jak Python, R, C++, Java i inne.\n",
        "\n",
        "**6. Wieloplatformowość:** Format HDF5 jest obsługiwany na różnych systemach operacyjnych, w tym na systemach Windows, macOS i Linux.\n",
        "\n",
        "**7. Wsparcie dla dużych zbiorów danych:** HDF5 jest efektywny w zarządzaniu dużymi zbiorami danych, co sprawia, że jest używany w dziedzinach nauki danych i uczenia maszynowego, gdzie dane mogą być bardzo obszerne.\n",
        "\n",
        "**8. Obsługa współbieżna:** Format HDF5 obsługuje dostęp współbieżny do plików, co pozwala na równoczesne operacje odczytu i zapisu z wielu źródeł.\n",
        "\n",
        "Te zalety czynią format HDF5 popularnym wyborem do przechowywania i wymiany danych w dziedzinach nauki danych, uczenia maszynowego, badań naukowych i wielu innych obszarach, gdzie efektywna organizacja i zarządzanie dużymi zbiorami danych są kluczowe. Popularne biblioteki takie jak h5py w Pythonie ułatwiają pracę z formatem HDF5 w ramach różnych zastosowań."
      ],
      "metadata": {
        "id": "ifsj0WrNpRIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pliki w formacie HDF5 mają zazwyczaj rozszerzenie `.h5`. Jest to powszechnie używane rozszerzenie dla plików HDF5 w różnych aplikacjach i językach programowania. Na przykład, jeśli korzystasz z biblioteki h5py w języku Python do tworzenia i obsługi plików HDF5, pliki te często mają rozszerzenie `.h5`.\n",
        "\n",
        "Przykład nazwy pliku HDF5: `moj_model.h5`\n",
        "\n",
        "Rozszerzenie `.h5` jest powszechnie używane w kontekście przechowywania modeli uczenia maszynowego, zbiorów danych, danych naukowych i innych typów danych, które można skompresować, hierarchicznie zorganizować i przenosić między różnymi platformami."
      ],
      "metadata": {
        "id": "o9_PJAtzpYgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generatory w uczeniu maszynowym"
      ],
      "metadata": {
        "id": "btdUx28-pezM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generatory są często stosowane w uczeniu maszynowym z kilku istotnych powodów:\n",
        "\n",
        "1. **Oszczędność pamięci:** Generatory pozwalają na leniwe ładowanie danych, co oznacza, że dane są wczytywane do pamięci w miarę potrzeb, a nie wczytywane w całości na początku. To jest szczególnie ważne, gdy pracujemy z dużymi zbiorami danych, które nie zmieszczą się w pamięci RAM.\n",
        "\n",
        "2. **Efektywność czasowa:** Generatory pozwalają na równoczesne wczytywanie danych i trening modelu. Dzięki temu można zmniejszyć czas oczekiwania na wczytanie wszystkich danych i rozpocząć trening szybciej.\n",
        "\n",
        "3. **Możliwość przetwarzania strumieniowego:** Generatory są idealne do przetwarzania danych strumieniowo, co jest przydatne w przypadku, gdy nowe dane stają się dostępne w miarę przetwarzania. Na przykład, gdy pracujemy z danymi w czasie rzeczywistym lub gdy dane są generowane dynamicznie.\n",
        "\n",
        "4. **Zasoby CPU/GPU:** Generatory pozwalają efektywnie zarządzać zasobami CPU/GPU, ponieważ dane są wczytywane tylko wtedy, gdy są potrzebne do obliczeń, co może ograniczyć obciążenie pamięci i przyspieszyć trening.\n",
        "\n",
        "5. **Możliwość pracy z nieskończonymi danymi:** Generatory pozwalają na pracę z nieskończonymi lub bardzo dużymi zbiorami danych, które nie mogą być wczytane do pamięci w całości. Przykładem może być przetwarzanie strumieni wideo lub dźwięku.\n",
        "\n",
        "6. **Augmentacja danych:** Generatory mogą być używane do generowania augmentowanych danych w czasie rzeczywistym podczas treningu, co pomaga w zwiększeniu różnorodności danych treningowych i poprawia zdolność generalizacji modelu.\n",
        "\n",
        "Przykładem użycia generatora w uczeniu maszynowym jest korzystanie z generatorów danych w bibliotece Keras, które mogą dostarczać dane do treningu modelu partiami (batchami) bez wczytywania całego zbioru danych do pamięci. To pozwala na efektywny trening modelu na dużych zbiorach danych bez obciążania pamięci RAM."
      ],
      "metadata": {
        "id": "tkSIAsaspqsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularyzacja w sieciach"
      ],
      "metadata": {
        "id": "UClZMgcqL2MK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Można stosować L1, L2"
      ],
      "metadata": {
        "id": "5v4ktATaPTZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Tworzenie modelu MLP z regularyzacją L1 i L2\n",
        "model = models.Sequential()\n",
        "\n",
        "# Dodanie warstwy wejściowej\n",
        "model.add(layers.InputLayer(input_shape=(4,)))\n",
        "\n",
        "# Dodanie warstw ukrytych z regularyzacją L1 i L2\n",
        "model.add(layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
        "model.add(layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "\n",
        "# Dodanie warstwy wyjściowej z funkcją aktywacji sigmoidalną (klasyfikacja binarna)\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Wyświetlenie informacji o modelu\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "b69ZxgyNPltH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Istnieją inne techniki reg. w sieciach - dedykowane dla sieci. Dropout - zachęcam."
      ],
      "metadata": {
        "id": "px9EfYlYP19x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zanikający/ eksplodujący gradient"
      ],
      "metadata": {
        "id": "J_yIjwkML8Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zanikający i eksplodujący gradient to problemy, które mogą wystąpić podczas procesu uczenia się sieci neuronowych, zwłaszcza w głębokich modelach. Oto krótkie wyjaśnienie obu problemów i sugestie dotyczące radzenia sobie z nimi:\n",
        "\n",
        "1. **Zanikający gradient:**\n",
        "   - Problem: W trakcie propagacji wstecznej, gradienty (pochodne) obliczane są dla wag w sieci. W przypadku zanikającego gradientu, gradienty dla wag w warstwach bliżej warstwy wejściowej stają się bardzo małe, co powoduje, że wagi w tych warstwach nie są aktualizowane, a model przestaje się uczyć.\n",
        "   - Rozwiązania:\n",
        "     - Używanie funkcji aktywacji, które są mniej podatne na zanikające gradienty, np. ReLU (Rectified Linear Unit).\n",
        "     - Użycie warstw normalizacji, takich jak Batch Normalization, aby utrzymać stabilność wewnętrznej korelacji w warstwach.\n",
        "     - Używanie odpowiednich inicjalizacji wag, takich jak He Initialization.\n",
        "\n",
        "2. **Eksplodujący gradient:**\n",
        "   - Problem: Eksplodujący gradient występuje, gdy gradienty stają się bardzo duże, co prowadzi do niestabilności i trudności w zbieganiu algorytmu optymalizacyjnego.\n",
        "   - Rozwiązania:\n",
        "     - Obcinanie gradientów: Stosowanie technik, takich jak gradient clipping, aby ograniczyć wartości gradientów w trakcie propagacji wstecznej.\n",
        "     - Używanie bardziej zaawansowanych optymalizatorów, takich jak Adam, które automatycznie dostosowują współczynniki uczenia.\n",
        "\n",
        "Podsumowując, stosowanie funkcji aktywacji, inicjalizacji wag, normalizacji i technik regularyzacji, oraz wybór odpowiedniego optymalizatora, mogą pomóc w radzeniu sobie z problemami zanikającego i eksplodującego gradientu. Ważne jest również doświadczenie i eksperymentowanie z różnymi konfiguracjami modelu w celu znalezienia najlepszych praktyk dla danego zadania."
      ],
      "metadata": {
        "id": "Vmvn1BcGNIqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procedury"
      ],
      "metadata": {
        "id": "kJl9j2ShL8J3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zadania:\n",
        "\n",
        "\n",
        "Napisać model - przygotować dane - wytrenować model\n",
        "\n",
        "Procedura:\n",
        "\n",
        "1. Napisać model\n",
        "2. Wykonać predykcję na losowym tensorze\n",
        "3. Skompiluje model\n",
        "4. Wykonam ewaluacje na losowych danych lub probce wlasciwych danych\n",
        "5. Wykonac trening na losowych danych\n",
        "6. Przygotowac dane do konca\n",
        "7. Powtorzyc kroki 2. - 5. na wlasciwych danych\n",
        "\n"
      ],
      "metadata": {
        "id": "zmxNJRkNMCgx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ue_3QnO4L4uV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}